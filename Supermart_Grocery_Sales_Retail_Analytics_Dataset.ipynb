{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPRoUd19+963X0soOuw/Nd/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Samplergithub769/Supermart-Grocery-Sales-Retail-Analysis/blob/main/Supermart_Grocery_Sales_Retail_Analytics_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "-4mDU0p_ISUh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MKcYqvaoH7wx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# remove warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load the Dataset**"
      ],
      "metadata": {
        "id": "FOFc6gX_IhkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Supermart Grocery Sales - Retail Analytics Dataset.csv')\n"
      ],
      "metadata": {
        "id": "Y5-O8qqEIbjW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "4044fd89-f81b-4cf8-dfab-1661fd77edb8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/Supermart Grocery Sales - Retail Analytics Dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-6dad25ad1444>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Supermart Grocery Sales - Retail Analytics Dataset.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Supermart Grocery Sales - Retail Analytics Dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first five rows of the dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "hOX-4Z7OJPEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Describe the dataset\n",
        "df.info()"
      ],
      "metadata": {
        "id": "juz59oieJ4H3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the shape of the data\n",
        "num_rows, num_cols = df.shape\n",
        "print(\"Shape of the Data:\")\n",
        "print(f\"Number of Rows: {num_rows}\")\n",
        "print(f\"Number of Columns: {num_cols}\\n\")"
      ],
      "metadata": {
        "id": "tg1rsGJKJ8yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Preprocessing**"
      ],
      "metadata": {
        "id": "wEWli_NPK9_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for missing values\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "N0MB82NTK0I7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert Date Columns to DateTime Format"
      ],
      "metadata": {
        "id": "UN5l46NgLb8E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert date with multiple formats\n",
        "\n",
        "def convert_date(date_str):\n",
        "\n",
        "    for fmt in ('%d-%m-%Y', '%m/%d/%Y'):\n",
        "\n",
        "        try:\n",
        "\n",
        "            return pd.to_datetime(date_str, format=fmt)\n",
        "\n",
        "        except ValueError:\n",
        "\n",
        "            continue\n",
        "\n",
        "    return pd.NaT  # Return NaT if no format matches\n",
        "\n",
        "# Apply the function to the 'Order Date' column\n",
        "df['Order Date'] = df['Order Date'].apply(convert_date)\n",
        "\n",
        "# Check for any NaT values after conversion\n",
        "print(df['Order Date'].isnull().sum(), \"dates could not be parsed.\")"
      ],
      "metadata": {
        "id": "mwooS4EJLEZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract day, month, and year from 'Order Date'\n",
        "df['Order Day'] = df['Order Date'].dt.day\n",
        "df['Order Month'] = df['Order Date'].dt.month\n",
        "df['Order Year'] = df['Order Date'].dt.year"
      ],
      "metadata": {
        "id": "ZZYDq3N-Le2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display first 5 rows to see the new columns\n",
        "print(df[['Order Date', 'Order Day', 'Order Month', 'Order Year']].head())"
      ],
      "metadata": {
        "id": "b8lNrR506lJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Check for Duplicates"
      ],
      "metadata": {
        "id": "9PO7Ef-KLq9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.duplicated().any()"
      ],
      "metadata": {
        "id": "HF1f1-aeLnFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Exploratory Data Analysis (EDA)**"
      ],
      "metadata": {
        "id": "fg-9K00gPL0G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 10 Cities by Sales Performance"
      ],
      "metadata": {
        "id": "WMsaw7jSPaHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze total sales by city to identify the top-performing location\n",
        "city_sales = df.groupby('City')['Sales'].sum().reset_index()\n",
        "city_sales.sort_values(by='Sales', ascending=False, inplace=True)\n",
        "# Plotting the top 10 cities by total sales\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.barplot(x='City', y='Sales', data=city_sales.head(10), palette='viridis')\n",
        "plt.title('Top 10 Cities by Total Sales')\n",
        "plt.xlabel('City')\n",
        "plt.ylabel('Total Sales')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bGxHhoodPGra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 10 Cities by Profit Performance."
      ],
      "metadata": {
        "id": "cU6MHcSpPpSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analyze total profit by city to identify the top-performing location\n",
        "city_sales = df.groupby('City')['Profit'].sum().reset_index()\n",
        "city_sales.sort_values(by='Profit', ascending=False, inplace=True)\n",
        "# Plotting the top 10 cities by total profit\n",
        "plt.figure(figsize=(12, 5))\n",
        "sns.barplot(x='City', y='Profit', data=city_sales.head(10), palette='viridis')\n",
        "plt.title('Top 10 Cities by Total Profit')\n",
        "plt.xlabel('City')\n",
        "plt.ylabel('Total Profit')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "z2Ld1Ar4PmZL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "city_sales"
      ],
      "metadata": {
        "id": "B0am9yzoP1bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sales Trend Over Time"
      ],
      "metadata": {
        "id": "Lk8yffd-P_if"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the monthly sales and profit data\n",
        "plt.figure(figsize=(12, 6))\n",
        "df.groupby(df['Order Date'].dt.to_period('M'))['Sales'].sum().plot(label='Monthly Total Sales')\n",
        "df.groupby(df['Order Date'].dt.to_period('M'))['Profit'].sum().plot(label='Monthly Total Profit')\n",
        "plt.title('Monthly Sales and Profit Data')\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Monthly Total Sales and Profit')\n",
        "plt.legend()\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.5)  # Added light grid lines\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NzH4qpiqP5bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the yearly sales and profit data\n",
        "plt.figure(figsize=(12, 6))\n",
        "df.groupby(df['Order Date'].dt.to_period('Y'))['Sales'].sum().plot(label='Yearly Total Sales')\n",
        "df.groupby(df['Order Date'].dt.to_period('Y'))['Profit'].sum().plot(label='Yearly Total Profit')\n",
        "plt.title('Yearly Sales and Profit Data')\n",
        "plt.xlabel('Yearly')\n",
        "plt.ylabel('Yearly Total Sales and Profit')\n",
        "plt.legend()\n",
        "plt.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.5)  # Added light grid lines\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vDqpiOJEQJYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Rate of Repeat Customers Over Time"
      ],
      "metadata": {
        "id": "R8qEiBNKQ7jB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract year and month\n",
        "df['month'] = df['Order Date'].dt.to_period('M').sort_values()\n",
        "\n",
        "# Get unique customers by month\n",
        "customers_by_month = df.groupby('month')['Customer Name'].nunique()\n",
        "\n",
        "\n",
        "\n",
        "# Initialize lists to store monthly retention rate values\n",
        "start_customers = []\n",
        "end_customers = []\n",
        "new_customers = []\n",
        "retention_rates = []\n",
        "\n",
        "\n",
        "\n",
        "# Loop over each month\n",
        "for i in range(1, len(customers_by_month)):\n",
        "    # Start customers (S)\n",
        "    start = customers_by_month.iloc[i-1]\n",
        "    # End customers (E)\n",
        "    end = customers_by_month.iloc[i]\n",
        "    # New customers (N) in the current month\n",
        "    current_month_customers = set(df[df['month'] == customers_by_month.index[i]]['Customer Name'])\n",
        "    previous_month_customers = set(df[df['month'] == customers_by_month.index[i-1]]['Customer Name'])\n",
        "    new_customers_in_month = len(current_month_customers - previous_month_customers)\n",
        "    # Calculate retention rate using the formula\n",
        "    retention_rate = ((end - new_customers_in_month) / start) * 100\n",
        "    # Append results to the lists\n",
        "    start_customers.append(start)\n",
        "    end_customers.append(end)\n",
        "    new_customers.append(new_customers_in_month)\n",
        "    retention_rates.append(retention_rate)\n",
        "# Create a DataFrame for retention rate data\n",
        "retention_df = pd.DataFrame({\n",
        "    'month': customers_by_month.index[1:],  # skip the first month\n",
        "    'start_customers': start_customers,\n",
        "    'end_customers': end_customers,\n",
        "    'new_customers': new_customers,\n",
        "    'retention_rate': retention_rates\n",
        "})\n",
        "# Plot the retention rate over time\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "plt.plot(retention_df['month'].astype(str), retention_df['retention_rate'], marker='o', color='b')\n",
        "\n",
        "plt.title('Repeat Customer Rate Overt Time')\n",
        "\n",
        "plt.xlabel('Month')\n",
        "\n",
        "plt.ylabel('Repeat Customer Rate (%)')\n",
        "\n",
        "plt.xticks(rotation=50)\n",
        "\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CMW3fxmtQSwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Average Purchase Value"
      ],
      "metadata": {
        "id": "uPOY1KV8R3fT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Monthly Average Purchase Value\n",
        "# Group by month and calculate total revenue and number of unique customers\n",
        "\n",
        "monthly_data = df.groupby('month').agg(\n",
        "\n",
        "    total_revenue=('Sales', 'sum'),\n",
        "\n",
        "    unique_customers=('Customer Name', pd.Series.nunique)\n",
        "\n",
        ").reset_index()\n",
        "\n",
        "# Calculate Average Customer Value (ACV)\n",
        "\n",
        "monthly_data['average_customer_value'] = monthly_data['total_revenue'] / monthly_data['unique_customers']\n",
        "\n",
        "# Plot Average Customer Value\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "plt.plot(monthly_data['month'].astype(str), monthly_data['average_customer_value'], marker='o')\n",
        "\n",
        "plt.title('Monthly Average Customer Value')\n",
        "\n",
        "plt.xlabel('Month')\n",
        "\n",
        "plt.ylabel('Average Customer Value')\n",
        "\n",
        "plt.xticks(rotation=80)\n",
        "\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "YgVeUVgBRrxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Yearly Average Purchase Value\n",
        "# Group by year and calculate total revenue and number of unique customers\n",
        "\n",
        "yearly_data = df.groupby('Order Year').agg(\n",
        "\n",
        "    total_revenue=('Sales', 'sum'),\n",
        "\n",
        "    unique_customers=('Customer Name', pd.Series.nunique)\n",
        "\n",
        ").reset_index()\n",
        "\n",
        "# Calculate Average Customer Value (ACV)\n",
        "\n",
        "yearly_data['average_customer_value'] = yearly_data['total_revenue'] / yearly_data['unique_customers']\n",
        "\n",
        "# Plot Average Customer Value\n",
        "\n",
        "plt.figure(figsize=(12,6))\n",
        "\n",
        "plt.plot(yearly_data['Order Year'].astype(str), yearly_data['average_customer_value'], marker='o')\n",
        "\n",
        "plt.title('Yearly Average Customer Value')\n",
        "\n",
        "plt.xlabel('Year')\n",
        "\n",
        "plt.ylabel('Average Customer Value')\n",
        "\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "OBLQFzrqSNNg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}